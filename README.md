# AGI_Hackathon
This is the repo for AGI- Hackathon. 

# Drafting idea for a AI enabled Ponting device or Caret. 

**The core idea is creating a smart pointing device. The pointing device(caret ?) has the following mechanics** 
1. Right click to create a context menu 
2. Click on the element to trigger an action 
3. Drag an element from one position to another
4. Drag to select elements

Can we add context through voice to the pointer ? Say we have the pointer hovered on a point. We can read the content underneath it. We speak on top of the pointer to command an action. The action could be 
1. Query 
2. Action - Cut Copy Paste 
3. Analysis - Extract meaning 
4. Use as a prompt. 

For each of these there needs to be a mechanic where, we select the elements underneath it. 

The caret can SELECT 
The caret can see the CONTEXT window the sentence 
The caret can PRINTS the text that is written throgh KEYBOARD 
The caret can EXECUTE COMMANDS through the voice. 

**The user story would be:**
1. The user starts to type the text. 
2. There is a visual highlighter that shows 
    2.1 The visual highlighter expands the with pressure , like word to sentence to pargraph , this could be an interesting interaction. 
3. The is voice input that the caret listens to and tries to understands what the user wants from th input text that is written. 
4. The caret generates text from the left side. 


 


