# AGI_Hackathon
This is the repo for AGI- Hackathon. 

# Using this place as a scratchpad

**The core idea is creating a smart pointing device. The pointing device has the following mechanics** 
1. Right click to create a context menu 
2. Click on the element to trigger an action 
3. Drag an element from one position to another
4. Drag to select elements

Can we add context through voice to the pointer ? Say we have the pointer hovered on a point. We can read the content underneath it. We speak on top of the pointer to command an action. The action could be 
1. Query 
2. Action - Cut Copy Paste 
3. Analysis - Extract meaning 
4. Use as a prompt. 






